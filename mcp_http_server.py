# -*- coding: utf-8 -*-
"""
HTTP MCP Server for Tree-Sitterä»£ç åˆ†æå™¨
æä¾›æ ‡å‡†çš„MCPåè®®æ¥å£ï¼Œè®©LLMèƒ½å¤Ÿé€šè¿‡HTTP/SSEè¿œç¨‹è®¿é—®ä»£ç ç»“æ„ä¿¡æ¯
åŸºäºStarletteå’ŒSSEä¼ è¾“
"""
import asyncio
import json
import logging
from pathlib import Path
from typing import Any, Dict, List, Optional, Sequence, Union
import sys
import uvicorn
from starlette.applications import Starlette
from starlette.routing import Route, Mount
from starlette.responses import Response

from src.sse_wrapper import CustomSseWrapper

# æ·»åŠ srcè·¯å¾„
sys.path.append(str(Path(__file__).parent / 'src'))

try:
    from mcp.server import Server
    from mcp.server.models import InitializationOptions
    from mcp.server.sse import SseServerTransport
    from mcp.types import (
        Resource, 
        Tool, 
        TextContent, 
        ImageContent, 
        EmbeddedResource
    )
    MCP_AVAILABLE = True
except ImportError:
    # å¦‚æœmcpåŒ…ä¸å¯ç”¨ï¼Œæä¾›ä¸€ä¸ªç®€åŒ–çš„å®ç°
    print("è­¦å‘Š: MCPåŒ…æœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–å®ç°")
    MCP_AVAILABLE = False
    
    class TextContent:
        def __init__(self, type: str, text: str):
            self.type = type
            self.text = text
    
    class ImageContent:
        def __init__(self, type: str, data: str):
            self.type = type
            self.data = data
    
    class EmbeddedResource:
        def __init__(self, type: str, resource: Any):
            self.type = type
            self.resource = resource
    
    class Tool:
        def __init__(self, name: str, description: str, inputSchema: Dict[str, Any]):
            self.name = name
            self.description = description
            self.inputSchema = inputSchema
    
    class InitializationOptions:
        def __init__(self, server_name: str, server_version: str, capabilities: Any):
            self.server_name = server_name
            self.server_version = server_version
            self.capabilities = capabilities
    
    class Server:
        def __init__(self, name: str):
            self.name = name
            self.tools = []
            self._list_tools_func = None
            self._call_tool_func = None
        
        def list_tools(self):
            def decorator(func):
                self._list_tools_func = func
                return func
            return decorator
        
        def call_tool(self):
            def decorator(func):
                self._call_tool_func = func
                return func
            return decorator
        
        def get_capabilities(self, notification_options=None, experimental_capabilities=None):
            return {"tools": True}
        
        async def run(self, read_stream, write_stream, options):
            print(f"ç®€åŒ–MCPæœåŠ¡å™¨ {self.name} å·²å¯åŠ¨")
            print("æ³¨æ„: è¿™æ˜¯ä¸€ä¸ªç®€åŒ–å®ç°ï¼Œä¸æä¾›å®Œæ•´çš„MCPåè®®æ”¯æŒ")
            # ç®€åŒ–å®ç°ï¼Œä»…ç”¨äºæµ‹è¯•
            await asyncio.sleep(1)

from src.analyzer import CodeAnalyzer
from src.config.analyzer_config import AnalyzerConfig
from src.knowledge.mcp_tools import MCPCodeTools
from src.knowledge.summary_generator import LayeredSummaryGenerator
from src.cache.analysis_cache import AnalysisCache
from src.path_resolver import PathResolver
from src.logging_setup import init_logging

# è®¾ç½®æ—¥å¿—ï¼šé›†ä¸­åŒ–åˆå§‹åŒ–ï¼Œå†™å…¥ logs/ å¹¶è¾“å‡ºåˆ°æ§åˆ¶å°
init_logging(app_name="tree-sitter-mcp-server", config_path="config/config.yaml", default_log_dir="logs")
logger = logging.getLogger("tree-sitter-mcp-server")

class TreeSitterMCPServer:
    """HTTP MCP Server using Starlette and SSE."""
    
    def __init__(self):
        self.server = Server("tree-sitter-code-analyzer")
        self.analyzer = None
        self.mcp_tools = None
        self.kg_data = None
        self.detailed_index = None
        self.current_project_path = None
        
        # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        self.cache_manager = AnalysisCache()
        
        # åˆå§‹åŒ–è·¯å¾„è§£æå™¨
        self.path_resolver = PathResolver()
        
        # æ³¨å†Œå·¥å…·
        self._register_tools()
    
    def _register_tools(self):
        """æ³¨å†ŒMCPå·¥å…·"""
        
        @self.server.list_tools()
        async def handle_list_tools() -> List[Tool]:
            """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„å·¥å…·"""
            return [
                Tool(
                    name="analyze_project",
                    description="åˆ†ææŒ‡å®šè·¯å¾„çš„C#é¡¹ç›®ï¼Œç”Ÿæˆä»£ç ç»“æ„æ¦‚è§ˆ",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "project_path": {
                                "type": "string",
                                "description": "è¦åˆ†æçš„é¡¹ç›®è·¯å¾„"
                            },
                            "language": {
                                "type": "string", 
                                "description": "ç¼–ç¨‹è¯­è¨€ï¼ˆé»˜è®¤csharpï¼‰",
                                "default": "csharp"
                            },
                            "compress": {
                                "type": "boolean",
                                "description": "æ˜¯å¦å‹ç¼©è¾“å‡ºï¼ˆæ¨ètrueï¼‰",
                                "default": True
                            }
                        },
                        "required": ["project_path"]
                    }
                ),
                Tool(
                    name="get_project_overview", 
                    description="è·å–å½“å‰é¡¹ç›®çš„æ¦‚è§ˆä¿¡æ¯",
                    inputSchema={
                        "type": "object",
                        "properties": {}
                    }
                ),
                Tool(
                    name="get_type_info",
                    description="è·å–æŒ‡å®šç±»å‹ï¼ˆç±»ã€æ¥å£ç­‰ï¼‰çš„è¯¦ç»†ä¿¡æ¯",
                    inputSchema={
                        "type": "object", 
                        "properties": {
                            "type_name": {
                                "type": "string",
                                "description": "ç±»å‹åç§°ï¼ˆå¦‚Userã€UserServiceç­‰ï¼‰"
                            }
                        },
                        "required": ["type_name"]
                    }
                ),
                Tool(
                    name="get_namespace_info",
                    description="è·å–æŒ‡å®šå‘½åç©ºé—´çš„è¯¦ç»†ä¿¡æ¯",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "namespace_name": {
                                "type": "string",
                                "description": "å‘½åç©ºé—´åç§°"
                            }
                        },
                        "required": ["namespace_name"]
                    }
                ),
                Tool(
                    name="get_relationships",
                    description="è·å–æŒ‡å®šç±»å‹çš„å…³ç³»ä¿¡æ¯ï¼ˆç»§æ‰¿ã€ä½¿ç”¨ç­‰ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "type_name": {
                                "type": "string",
                                "description": "ç±»å‹åç§°"
                            }
                        },
                        "required": ["type_name"]
                    }
                ),
                Tool(
                    name="get_method_details",
                    description="è·å–æŒ‡å®šæ–¹æ³•çš„è¯¦ç»†ä¿¡æ¯",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "class_name": {
                                "type": "string",
                                "description": "ç±»å"
                            },
                            "method_name": {
                                "type": "string", 
                                "description": "æ–¹æ³•å"
                            }
                        },
                        "required": ["class_name", "method_name"]
                    }
                ),
                Tool(
                    name="get_architecture_info",
                    description="è·å–é¡¹ç›®çš„æ¶æ„è®¾è®¡ä¿¡æ¯",
                    inputSchema={
                        "type": "object",
                        "properties": {}
                    }
                ),
                Tool(
                    name="list_all_types",
                    description="åˆ—å‡ºé¡¹ç›®ä¸­çš„æ‰€æœ‰ç±»å‹",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "type_filter": {
                                "type": "string",
                                "description": "ç±»å‹è¿‡æ»¤å™¨ï¼ˆclassã€interfaceã€enumç­‰ï¼Œé»˜è®¤å…¨éƒ¨ï¼‰"
                            }
                        }
                    }
                ),
                Tool(
                    name="clear_cache",
                    description="æ¸…é™¤åˆ†æç¼“å­˜ï¼ˆå¯æŒ‡å®šé¡¹ç›®æˆ–æ¸…é™¤å…¨éƒ¨ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "project_path": {
                                "type": "string",
                                "description": "è¦æ¸…é™¤ç¼“å­˜çš„é¡¹ç›®è·¯å¾„ï¼ˆä¸æä¾›åˆ™æ¸…é™¤å…¨éƒ¨ç¼“å­˜ï¼‰"
                            },
                            "language": {
                                "type": "string",
                                "description": "ç¼–ç¨‹è¯­è¨€ï¼ˆé»˜è®¤csharpï¼‰",
                                "default": "csharp"
                            }
                        }
                    }
                ),
                Tool(
                    name="get_cache_stats",
                    description="è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯",
                    inputSchema={
                        "type": "object",
                        "properties": {}
                    }
                ),
                Tool(
                    name="list_user_projects",
                    description="åˆ—å‡ºæŒ‡å®šç”¨æˆ·çš„æ‰€æœ‰é¡¹ç›®ï¼Œè¿”å›é¡¹ç›®çš„ç»å¯¹è·¯å¾„",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "username": {
                                "type": "string",
                                "description": "ç”¨æˆ·åï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤ç”¨æˆ·ï¼‰"
                            }
                        }
                    }
                )
            ]
        
        @self.server.call_tool()
        async def handle_call_tool(name: str, arguments: Dict[str, Any]) -> Sequence[Union[TextContent, ImageContent, EmbeddedResource]]:
            """å¤„ç†å·¥å…·è°ƒç”¨"""
            try:
                if name == "analyze_project":
                    return await self._analyze_project(arguments)
                elif name == "get_project_overview":
                    return await self._get_project_overview(arguments)
                elif name == "get_type_info":
                    return await self._get_type_info(arguments)
                elif name == "get_namespace_info":
                    return await self._get_namespace_info(arguments)
                elif name == "get_relationships":
                    return await self._get_relationships(arguments)
                elif name == "get_method_details":
                    return await self._get_method_details(arguments)
                elif name == "get_architecture_info":
                    return await self._get_architecture_info(arguments)
                elif name == "list_all_types":
                    return await self._list_all_types(arguments)
                elif name == "clear_cache":
                    return await self._clear_cache(arguments)
                elif name == "get_cache_stats":
                    return await self._get_cache_stats(arguments)
                elif name == "list_user_projects":
                    return await self._list_user_projects(arguments)
                else:
                    return [TextContent(type="text", text=f"æœªçŸ¥å·¥å…·: {name}")]
            
            except Exception as e:
                logger.error(f"å·¥å…·è°ƒç”¨é”™è¯¯ {name}: {e}")
                return [TextContent(type="text", text=f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}")]
    
    async def _analyze_project(self, args: Dict[str, Any]) -> Sequence[TextContent]:
        """åˆ†æé¡¹ç›®ï¼ˆæ”¯æŒç¼“å­˜ï¼‰"""
        project_path = args.get("project_path", ".")
        language = args.get("language", "csharp")
        compress = args.get("compress", True)
        
        try:
            # è·å–æ–‡ä»¶æ‰©å±•å
            language_extensions = {
                'csharp': ['cs'],
                'python': ['py'],
                'java': ['java'],
                'javascript': ['js'],
                'typescript': ['ts']
            }
            file_extensions = language_extensions.get(language, ['cs'])
            
            # æ£€æŸ¥ç¼“å­˜
            logger.info(f" æ£€æŸ¥é¡¹ç›®ç¼“å­˜: {project_path}")
            has_changed = self.cache_manager.has_project_changed(project_path, language, file_extensions)
            
            if not has_changed:
                # ä½¿ç”¨ç¼“å­˜
                logger.info(" ä½¿ç”¨ç¼“å­˜æ•°æ®")
                cached_data = self.cache_manager.load_project_cache(project_path, language)
                
                if cached_data:
                    # ä¿å­˜å½“å‰é¡¹ç›®ä¿¡æ¯
                    self.current_project_path = project_path
                    self.kg_data = cached_data['kg_data']
                    self.detailed_index = cached_data['detailed_index']
                    
                    # åˆå§‹åŒ–MCPå·¥å…·
                    self.mcp_tools = MCPCodeTools()
                    self.mcp_tools.kg_data = self.kg_data
                    self.mcp_tools.set_detailed_index(self.detailed_index)
                    
                    # ç”Ÿæˆåˆ†å±‚æ‘˜è¦
                    summary_generator = LayeredSummaryGenerator()
                    summaries = summary_generator.generate_multilevel_summaries(self.kg_data)
                    
                    # è·å–ç¼“å­˜ä¿¡æ¯
                    cache_info = cached_data['cache_info']
                    cached_at = cache_info.get('cached_at', 0)
                    file_count = cache_info.get('file_count', 0)
                    
                    import datetime
                    cached_time = datetime.datetime.fromtimestamp(cached_at).strftime('%Y-%m-%d %H:%M:%S')
                    
                    overview = summaries.get('overview', 'é¡¹ç›®åˆ†æå®Œæˆ')
                    navigation = summaries.get('navigation', 'å¯¼èˆªç´¢å¼•ç”Ÿæˆå®Œæˆ')
                    
                    response = f"""é¡¹ç›®åˆ†æå®Œæˆï¼ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰

{overview}

---

{navigation}

åˆ†æç»Ÿè®¡
- æ€»èŠ‚ç‚¹æ•°: {self.kg_data.get('statistics', {}).get('total_nodes', 0)}
- æ€»å…³ç³»æ•°: {self.kg_data.get('statistics', {}).get('total_relationships', 0)}
- é¡¹ç›®è·¯å¾„: {project_path}
- å‹ç¼©æ¨¡å¼: {'å¯ç”¨' if compress else 'ç¦ç”¨'}

ç¼“å­˜ä¿¡æ¯
- ç¼“å­˜æ—¶é—´: {cached_time}
- æ–‡ä»¶æ•°é‡: {file_count}
- ç¼“å­˜çŠ¶æ€: æœ‰æ•ˆ

ç°åœ¨å¯ä»¥ä½¿ç”¨ä¸Šè¿°å·¥å…·è¿›è¡Œè¯¦ç»†æŸ¥è¯¢äº†ï¼
"""
                    
                    return [TextContent(type="text", text=response)]
            
            # éœ€è¦é‡æ–°åˆ†æ
            logger.info(" é¡¹ç›®å·²æ”¹å˜ï¼Œé‡æ–°åˆ†æ...")
            
            # é…ç½®åˆ†æå™¨
            config = AnalyzerConfig()
            config.set('input.path', project_path)
            config.set('input.language', language)
            config.set('knowledge_graph.compress_members', compress)
            config.set('output.formats', ['json', 'llm_prompt'])
            config.set('logging.level', 'ERROR')
            
            # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
            import tempfile
            with tempfile.TemporaryDirectory() as temp_dir:
                config.set('output.directory', temp_dir)
                
                # æ‰§è¡Œåˆ†æ
                self.analyzer = CodeAnalyzer(config)
                result = self.analyzer.analyze()
                
                if not result['success']:
                    return [TextContent(type="text", text=f"åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")]
                
                # ä¿å­˜å½“å‰é¡¹ç›®ä¿¡æ¯
                self.current_project_path = project_path
                
                # è¯»å–ç”Ÿæˆçš„æ•°æ®
                kg_file = Path(temp_dir) / 'knowledge_graph.json'
                with open(kg_file, 'r', encoding='utf-8') as f:
                    self.kg_data = json.load(f)
                
                # ç”Ÿæˆåˆ†å±‚æ‘˜è¦
                summary_generator = LayeredSummaryGenerator()
                summaries = summary_generator.generate_multilevel_summaries(self.kg_data)
                self.detailed_index = summaries.get('detailed_index', {})
                
                # åˆå§‹åŒ–MCPå·¥å…·
                self.mcp_tools = MCPCodeTools()
                self.mcp_tools.kg_data = self.kg_data
                self.mcp_tools.set_detailed_index(self.detailed_index)
                
                # ä¿å­˜åˆ°ç¼“å­˜
                logger.info(" ä¿å­˜åˆ†æç»“æœåˆ°ç¼“å­˜...")
                self.cache_manager.save_project_cache(
                    project_path, language, file_extensions, 
                    self.kg_data, self.detailed_index
                )
                
                # è¿”å›æ¦‚è§ˆä¿¡æ¯
                overview = summaries.get('overview', 'é¡¹ç›®åˆ†æå®Œæˆ')
                navigation = summaries.get('navigation', 'å¯¼èˆªç´¢å¼•ç”Ÿæˆå®Œæˆ')
                
                stats = result['statistics']
                
                response = f"""é¡¹ç›®åˆ†æå®Œæˆï¼

{overview}

---

{navigation}

åˆ†æç»Ÿè®¡
- æ€»èŠ‚ç‚¹æ•°: {stats['total_nodes']}
- æ€»å…³ç³»æ•°: {stats['total_relationships']}
- é¡¹ç›®è·¯å¾„: {project_path}
- å‹ç¼©æ¨¡å¼: {'å¯ç”¨' if compress else 'ç¦ç”¨'}

ç¼“å­˜ä¿¡æ¯
- ç¼“å­˜çŠ¶æ€: å·²ä¿å­˜
- ä¸‹æ¬¡åˆ†æå°†ä½¿ç”¨ç¼“å­˜ï¼ˆé™¤éæ–‡ä»¶å‘ç”Ÿå˜åŒ–ï¼‰

ç°åœ¨å¯ä»¥ä½¿ç”¨ä¸Šè¿°å·¥å…·è¿›è¡Œè¯¦ç»†æŸ¥è¯¢äº†ï¼
"""
                
                return [TextContent(type="text", text=response)]
        
        except Exception as e:
            return [TextContent(type="text", text=f"åˆ†æé¡¹ç›®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")]
    
    async def _get_project_overview(self, args: Dict[str, Any]) -> Sequence[TextContent]:
        """è·å–é¡¹ç›®æ¦‚è§ˆ"""
        if not self.kg_data:
            return [TextContent(type="text", text="è¯·å…ˆä½¿ç”¨ analyze_project å·¥å…·åˆ†æé¡¹ç›®")]
        
        stats = self.kg_data.get('statistics', {})
        node_types = stats.get('node_types', {})
        
        overview = f"""é¡¹ç›®æ¦‚è§ˆ

é¡¹ç›®è·¯å¾„: {self.current_project_path or 'æœªçŸ¥'}

ä»£ç ç»Ÿè®¡
"""
        
        for node_type, count in node_types.items():
            overview += f"- {node_type}: {count}ä¸ª\n"
        
        overview += f"\næ€»è®¡: {stats.get('total_nodes', 0)}ä¸ªä»£ç å…ƒç´ ï¼Œ{stats.get('total_relationships', 0)}ä¸ªå…³ç³»"
        
        return [TextContent(type="text", text=overview)]
    
    async def _get_type_info(self, args: Dict[str, Any]) -> Sequence[TextContent]:
        """è·å–ç±»å‹ä¿¡æ¯"""
        if not self.mcp_tools:
            return [TextContent(type="text", text="è¯·å…ˆä½¿ç”¨ analyze_project å·¥å…·åˆ†æé¡¹ç›®")]
        
        type_name = args.get("type_name")
        result = self.mcp_tools.get_type_info(type_name)
        
        # å¦‚æœæ˜¯è·å–æ‰€æœ‰ç±»å‹
        if 'all_types' in result:
            response = "æ‰€æœ‰ç±»å‹åˆ—è¡¨:\n\n"
            types_by_category = {}
            
            # æŒ‰ç±»å‹åˆ†ç»„
            for name, type_info in result['all_types'].items():
                type_category = type_info['type']
                if type_category not in types_by_category:
                    types_by_category[type_category] = []
                types_by_category[type_category].append(type_info)
            
            # æ˜¾ç¤ºå„ç±»å‹
            for category, types in types_by_category.items():
                response += f"{category.capitalize()}ç±»å‹:\n"
                for type_info in types:
                    modifiers = type_info.get('modifiers', [])
                    modifiers_str = ' '.join(modifiers) + ' ' if modifiers else ''
                    response += f"  {modifiers_str}{type_info['name']}\n"
                response += "\n"
            
            return [TextContent(type="text", text=response)]
        
        if 'error' in result:
            return [TextContent(type="text", text=f"{result['error']}")]
        
        # æ ¼å¼åŒ–è¾“å‡ºï¼Œå°†ä¿®é¥°ç¬¦é›†æˆåˆ°ç±»åå‰é¢
        modifiers = result.get('modifiers', [])
        modifiers_str = ' '.join(modifiers) + ' ' if modifiers else ''
        type_display = f"{modifiers_str}{result['type']}"
        
        response = f"{type_display.capitalize()}: {result['name']}\n"
        
        # åŸºæœ¬ä¿¡æ¯
        if result.get('base_types'):
            response += f"ç»§æ‰¿è‡ª: {', '.join(result['base_types'])}\n"
        
        if result.get('is_generic'):
            response += f"æ³›å‹: æ˜¯\n"
        
        response += "\næˆå‘˜ä¿¡æ¯:\n"
        
        # æˆå‘˜è¯¦æƒ…
        members = result.get('members', {})
        
        if members.get('constructors'):
            response += "\næ„é€ å‡½æ•°:\n"
            for ctor in members['constructors']:
                signature = ctor.get('signature', f"{ctor['name']}()")
                modifiers = ctor.get('modifiers', [])
                modifier_str = ' '.join(modifiers) + ' ' if modifiers else ''
                response += f"  {modifier_str}{signature}\n"
        
        if members.get('methods'):
            response += "\næ–¹æ³•:\n"
            for method in members['methods']:
                signature = method.get('signature', f"{method['name']}()")
                modifiers = method.get('modifiers', [])
                modifier_str = ' '.join(modifiers) + ' ' if modifiers else ''
                response += f"  {modifier_str}{signature}\n"
        
        if members.get('properties'):
            response += "\nå±æ€§:\n"
            for prop in members['properties']:
                response += f"  {prop['name']}: {prop.get('type', 'unknown')}\n"
        
        if members.get('fields'):
            response += "\nå­—æ®µ:\n"
            for field in members['fields']:
                response += f"  {field['name']}: {field.get('type', 'unknown')}\n"
        
        return [TextContent(type="text", text=response)]
    
    async def _search_methods(self, args: Dict[str, Any]) -> Sequence[TextContent]:
        """æœç´¢æ–¹æ³•"""
        if not self.mcp_tools:
            return [TextContent(type="text", text="è¯·å…ˆä½¿ç”¨ analyze_project å·¥å…·åˆ†æé¡¹ç›®")]
        
        keyword = args.get("keyword")
        limit = args.get("limit", 10)
        
        result = self.mcp_tools.search_methods(keyword, limit)
        
        response = f"#  æœç´¢ç»“æœ: '{keyword}'\n\n"
        response += f"æ‰¾åˆ° {result['total_found']} ä¸ªç›¸å…³æ–¹æ³•\n\n"
        
        if result['methods']:
            response += "## ğŸ“‹ åŒ¹é…çš„æ–¹æ³•\n\n"
            for i, method in enumerate(result['methods'], 1):
                response += f"### {i}. {method['class']}.{method['method']['name']}\n"
                response += f"**ç­¾å**: {method['signature']}\n"
                operations = ', '.join(method['method'].get('operations', []))
                if operations:
                    response += f"**æ“ä½œ**: {operations}\n"
                if method.get('context'):
                    response += f"**ä¸Šä¸‹æ–‡**: {method['context']}\n"
                response += "\n"
        else:
            response += " æœªæ‰¾åˆ°åŒ¹é…çš„æ–¹æ³•"
        
        return [TextContent(type="text", text=response)]
    
    async def _get_namespace_info(self, args: Dict[str, Any]) -> Sequence[TextContent]:
        """è·å–å‘½åç©ºé—´ä¿¡æ¯"""
        if not self.mcp_tools:
            return [TextContent(type="text", text="è¯·å…ˆä½¿ç”¨ analyze_project å·¥å…·åˆ†æé¡¹ç›®")]
        
        namespace_name = args.get("namespace_name")
        result = self.mcp_tools.get_namespace_info(namespace_name)
        
        if 'error' in result:
            return [TextContent(type="text", text=f"{result['error']}")]
        
        response = f"å‘½åç©ºé—´: {result['namespace']}\n\n"
        response += f"{result['summary']}\n\n"
        
        if result['types_detail']:
            response += "åŒ…å«çš„ç±»å‹:\n\n"
            
            # æŒ‰methodsæ•°é‡æ’åºç±»å‹
            sorted_types = sorted(
                result['types_detail'], 
                key=lambda x: x.get('member_counts', {}).get('methods', 0), 
                reverse=True
            )
            
            for type_info in sorted_types:
                response += f"{type_info['type'].capitalize()}: {type_info['name']}\n"
                if type_info.get('modifiers'):
                    response += f"  ä¿®é¥°ç¬¦: {', '.join(type_info['modifiers'])}\n"
                
                member_counts = type_info.get('member_counts', {})
                if member_counts:
                    counts = [f"{k}: {v}" for k, v in member_counts.items() if v > 0]
                    if counts:
                        response += f"  æˆå‘˜: {', '.join(counts)}\n"
                response += "\n"
        
        return [TextContent(type="text", text=response)]
    
    async def _get_relationships(self, args: Dict[str, Any]) -> Sequence[TextContent]:
        """è·å–å…³ç³»ä¿¡æ¯"""
        if not self.mcp_tools:
            return [TextContent(type="text", text="è¯·å…ˆä½¿ç”¨ analyze_project å·¥å…·åˆ†æé¡¹ç›®")]
        
        type_name = args.get("type_name")
        result = self.mcp_tools.get_relationships(type_name)
        
        # å¦‚æœæ˜¯è·å–æ‰€æœ‰å…³ç³»
        if 'all_relationships' in result:
            response = "æ‰€æœ‰ç»§æ‰¿å’Œä½¿ç”¨å…³ç³»:\n\n"
            all_relationships = result['all_relationships']
            
            # æ˜¾ç¤ºç»§æ‰¿å…³ç³»
            if all_relationships['inherits_from']:
                response += "ç»§æ‰¿å…³ç³»:\n"
                for rel in all_relationships['inherits_from'][:20]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                    response += f"  {rel['from']} -> {rel['to']} ({rel['type']})\n"
                if len(all_relationships['inherits_from']) > 20:
                    response += f"  ... è¿˜æœ‰ {len(all_relationships['inherits_from']) - 20} ä¸ªç»§æ‰¿å…³ç³»\n"
                response += "\n"
            
            # æ˜¾ç¤ºä½¿ç”¨å…³ç³»
            if all_relationships['uses']:
                response += "ä½¿ç”¨å…³ç³»:\n"
                for rel in all_relationships['uses'][:20]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                    response += f"  {rel['from']} -> {rel['to']} ({rel['type']})\n"
                if len(all_relationships['uses']) > 20:
                    response += f"  ... è¿˜æœ‰ {len(all_relationships['uses']) - 20} ä¸ªä½¿ç”¨å…³ç³»\n"
                response += "\n"
            
            return [TextContent(type="text", text=response)]
        
        if 'error' in result:
            return [TextContent(type="text", text=f"{result['error']}")]
        
        response = f"{result['type_name']} çš„å…³ç³»å›¾\n\n"
        response += f"æ€»ç»“: {result['summary']}\n\n"
        
        relationships = result['relationships']
        
        for rel_type, targets in relationships.items():
            if targets:
                rel_name_map = {
                    'inherits_from': 'ç»§æ‰¿è‡ª',
                    'inherited_by': 'è¢«ç»§æ‰¿', 
                    'uses': 'ä½¿ç”¨',
                    'used_by': 'è¢«ä½¿ç”¨',
                    'contains': 'åŒ…å«',
                    'contained_in': 'ä½äº'
                }
                
                response += f"{rel_name_map.get(rel_type, rel_type)}:\n"
                for target in targets:
                    response += f"  {target}\n"
                response += "\n"
        
        return [TextContent(type="text", text=response)]
    
    async def _get_method_details(self, args: Dict[str, Any]) -> Sequence[TextContent]:
        """è·å–æ–¹æ³•è¯¦æƒ…"""
        if not self.mcp_tools:
            return [TextContent(type="text", text="è¯·å…ˆä½¿ç”¨ analyze_project å·¥å…·åˆ†æé¡¹ç›®")]
        
        class_name = args.get("class_name")
        method_name = args.get("method_name")
        
        result = self.mcp_tools.get_method_details(class_name, method_name)
        
        if 'error' in result:
            return [TextContent(type="text", text=f" {result['error']}")]
        
        response = f"#  æ–¹æ³•è¯¦æƒ…: {result['class']}.{result['method_name']}\n\n"
        
        response += f"**ç­¾å**: {result['signature']}\n"
        response += f"**è¿”å›ç±»å‹**: {result['return_type']}\n"
        
        if result.get('modifiers'):
            response += f"**ä¿®é¥°ç¬¦**: {', '.join(result['modifiers'])}\n"
        
        operations = result.get('operations', [])
        if operations:
            response += f"**æ“ä½œç±»å‹**: {', '.join(operations)}\n"
        
        response += "\n## ğŸ“‹ å‚æ•°\n\n"
        parameters = result.get('parameters', [])
        if parameters:
            for param in parameters:
                param_type = param.get('type', 'unknown')
                param_name = param.get('name', 'unknown') 
                param_mods = param.get('modifiers', [])
                mod_str = f" ({', '.join(param_mods)})" if param_mods else ""
                response += f"- **{param_name}**: {param_type}{mod_str}\n"
        else:
            response += "æ— å‚æ•°\n"
        
        response += "\n## ğŸ·ï¸ ç‰¹æ€§\n\n"
        characteristics = result.get('characteristics', {})
        for key, value in characteristics.items():
            if value:
                key_map = {
                    'is_abstract': 'æŠ½è±¡æ–¹æ³•',
                    'is_virtual': 'è™šæ–¹æ³•',
                    'is_override': 'é‡å†™æ–¹æ³•',
                    'is_static': 'é™æ€æ–¹æ³•',
                    'is_public': 'å…¬å…±æ–¹æ³•'
                }
                response += f" {key_map.get(key, key)}\n"
        
        suggestions = result.get('usage_suggestions', [])
        if suggestions:
            response += f"\n##  ä½¿ç”¨å»ºè®®\n\n"
            for suggestion in suggestions:
                response += f"- {suggestion}\n"
        
        return [TextContent(type="text", text=response)]
    
    async def _get_architecture_info(self, args: Dict[str, Any]) -> Sequence[TextContent]:
        """è·å–æ¶æ„ä¿¡æ¯"""
        if not self.mcp_tools:
            return [TextContent(type="text", text="è¯·å…ˆä½¿ç”¨ analyze_project å·¥å…·åˆ†æé¡¹ç›®")]
        
        result = self.mcp_tools.get_architecture_info()
        
        if 'error' in result:
            return [TextContent(type="text", text=f" {result['error']}")]
        
        response = "ç³»ç»Ÿæ¶æ„åˆ†æ\n\n"
        
        # æ¶æ„æ¦‚è¦
        response += f"æ¶æ„æ¦‚è¦\n{result.get('architecture_summary', '')}"
        
        # å‘½åç©ºé—´å±‚æ¬¡
        namespaces = result.get('namespace_hierarchy', {})
        if namespaces:
            response += "\n\nå‘½åç©ºé—´å±‚æ¬¡\n"
            for ns, info in namespaces.items():
                response += f"\n{ns} ({info['total_types']}ä¸ªç±»å‹)\n"
                for type_name, types in info['types'].items():
                    if types:
                        response += f"- {type_name}: {', '.join(types[:5])}"
                        if len(types) > 5:
                            response += f" ç­‰{len(types)}ä¸ª"
                        response += "\n"
        
        # ç±»ä¾èµ–å…³ç³»
        dependencies = result.get('class_dependencies', {})
        if dependencies:
            response += "\nç±»ä¾èµ–å…³ç³»\n"
            for class_name, deps in list(dependencies.items())[:8]:  # åªæ˜¾ç¤ºå‰8ä¸ª
                response += f"\n{class_name}\n"
                for dep in deps[:5]:  # æ¯ä¸ªç±»åªæ˜¾ç¤ºå‰5ä¸ªä¾èµ–
                    response += f"- {dep}\n"
        
        # æ¥å£å®ç°
        implementations = result.get('interface_implementations', {})
        if implementations:
            response += "\næ¥å£å®ç°å…³ç³»\n"
            for interface, implementers in implementations.items():
                response += f"\n{interface}\n"
                response += f"å®ç°ç±»: {', '.join(implementers)}\n"
        
        # ç»§æ‰¿å…³ç³»
        inheritance = result.get('inheritance_chains', {})
        base_classes = inheritance.get('base_classes', {})
        if base_classes:
            response += "\nç»§æ‰¿å…³ç³»\n"
            for base_class, derived_classes in list(base_classes.items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                response += f"\n{base_class} åŸºç±»\n"
                response += f"æ´¾ç”Ÿç±»: {', '.join(derived_classes)}\n"
        
        # ç»„åˆå…³ç³»  
        composition = result.get('composition_relationships', {})
        if composition:
            response += "\nç»„åˆå…³ç³»\n"
            for container, contained in list(composition.items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                response += f"\n{container}\n"
                response += f"åŒ…å«: {', '.join(contained[:5])}\n"
                if len(contained) > 5:
                    response += f"ç­‰{len(contained)}ä¸ªç»„ä»¶\n"
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç±»å‹ï¼Œæ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        debug_info = result.get('debug_info', {})
        if debug_info and all(info['total_types'] == 0 for info in result.get('namespace_hierarchy', {}).values()):
            response += "\nè°ƒè¯•ä¿¡æ¯\n"
            response += "æ£€æµ‹åˆ°æ‰€æœ‰å‘½åç©ºé—´éƒ½æ˜¾ç¤º0ä¸ªç±»å‹ï¼Œä»¥ä¸‹æ˜¯è°ƒè¯•ä¿¡æ¯ï¼š\n\n"
            
            sample_nodes = debug_info.get('sample_nodes', [])
            if sample_nodes:
                response += "èŠ‚ç‚¹æ ·æœ¬:\n"
                for node in sample_nodes:
                    response += f"- {node['type']}: {node['name']} (ID: {node['id']})\n"
            
            node_id_patterns = debug_info.get('node_id_patterns', [])
            if node_id_patterns:
                response += f"\nIDæ¨¡å¼: {', '.join(node_id_patterns[:5])}\n"
            
            metadata_samples = debug_info.get('metadata_samples', [])
            if metadata_samples:
                response += "\nMetadataç»“æ„:\n"
                for meta in metadata_samples:
                    response += f"- {meta['node_name']} ({meta['node_type']}): {', '.join(meta['metadata_keys'])}\n"
            
            # æ–°å¢: å‘½åç©ºé—´åˆ†æè°ƒè¯•
            ns_analysis = debug_info.get('namespace_analysis', {})
            if ns_analysis:
                response += "\nå‘½åç©ºé—´åˆ†æ:\n"
                response += f"- æ€»å‘½åç©ºé—´æ•°: {ns_analysis.get('total_namespaces', 0)}\n"
                response += f"- æ€»ç±»æ•°: {ns_analysis.get('total_classes', 0)}\n"
                
                ns_samples = ns_analysis.get('namespace_samples', [])
                if ns_samples:
                    response += "\nå‘½åç©ºé—´æ ·æœ¬:\n"
                    for ns in ns_samples:
                        response += f"- {ns['name']} (ID: {ns['id']})\n"
                
                class_samples = ns_analysis.get('class_samples', [])
                if class_samples:
                    response += "\nç±»æ ·æœ¬:\n"
                    for cls in class_samples:
                        response += f"- {cls['name']} (ID: {cls['id']})\n"
                
                matching_attempts = ns_analysis.get('id_matching_attempts', [])
                if matching_attempts:
                    response += "\nIDåŒ¹é…å°è¯•:\n"
                    for attempt in matching_attempts:
                        response += f"- ç±» {attempt['class_name']} (ID: {attempt['class_id']})\n"
                        if attempt['potential_namespace_ids']:
                            response += f"  æ½œåœ¨å‘½åç©ºé—´ID: {', '.join(attempt['potential_namespace_ids'])}\n"
                        if attempt['matched_namespaces']:
                            response += f"  åŒ¹é…çš„å‘½åç©ºé—´: {', '.join(attempt['matched_namespaces'])}\n"
                        else:
                            response += "  æœªæ‰¾åˆ°åŒ¹é…çš„å‘½åç©ºé—´\n"
        
        return [TextContent(type="text", text=response)]
    
    async def _list_all_types(self, args: Dict[str, Any]) -> Sequence[TextContent]:
        """åˆ—å‡ºæ‰€æœ‰ç±»å‹"""
        if not self.kg_data:
            return [TextContent(type="text", text="è¯·å…ˆä½¿ç”¨ analyze_project å·¥å…·åˆ†æé¡¹ç›®")]
        
        type_filter = args.get("type_filter", "").lower()
        
        response = "é¡¹ç›®ä¸­çš„æ‰€æœ‰ç±»å‹\n\n"
        
        # æŒ‰ç±»å‹åˆ†ç»„
        types_by_category = {}
        
        for node in self.kg_data.get('nodes', []):
            if node['type'] in ['class', 'interface', 'struct', 'enum']:
                node_type = node['type']
                
                # åº”ç”¨è¿‡æ»¤å™¨
                if type_filter and type_filter not in node_type:
                    continue
                
                if node_type not in types_by_category:
                    types_by_category[node_type] = []
                
                types_by_category[node_type].append(node)
        
        for type_name, types in types_by_category.items():
            response += f"{type_name.capitalize()}s ({len(types)}ä¸ª)\n\n"
            
            for type_node in types:
                response += f"- {type_node['name']}"
                
                # æ·»åŠ ä¿®é¥°ç¬¦ä¿¡æ¯
                modifiers = type_node.get('metadata', {}).get('modifiers', [])
                if modifiers:
                    response += f" ({', '.join(modifiers)})"
                
                # æ·»åŠ ç»§æ‰¿ä¿¡æ¯
                base_types = type_node.get('metadata', {}).get('base_types', [])
                if base_types:
                    response += f" ç»§æ‰¿è‡ª: {', '.join(base_types)}"
                
                response += "\n"
            
            response += "\n"
        
        if not types_by_category:
            response += "æœªæ‰¾åˆ°åŒ¹é…çš„ç±»å‹"
        
        return [TextContent(type="text", text=response)]
    
    async def _clear_cache(self, args: Dict[str, Any]) -> Sequence[TextContent]:
        """æ¸…é™¤ç¼“å­˜"""
        project_path = args.get("project_path")
        language = args.get("language", "csharp")
        
        try:
            if project_path:
                # æ¸…é™¤ç‰¹å®šé¡¹ç›®ç¼“å­˜
                self.cache_manager.clear_cache(project_path, language)
                response = f"å·²æ¸…é™¤é¡¹ç›®ç¼“å­˜: {project_path}"
            else:
                # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
                self.cache_manager.clear_cache()
                response = "å·²æ¸…é™¤æ‰€æœ‰ç¼“å­˜"
            
            return [TextContent(type="text", text=response)]
            
        except Exception as e:
            return [TextContent(type="text", text=f"æ¸…é™¤ç¼“å­˜å¤±è´¥: {str(e)}")]
    
    async def _get_cache_stats(self, args: Dict[str, Any]) -> Sequence[TextContent]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats = self.cache_manager.get_cache_stats()
            
            if 'error' in stats:
                return [TextContent(type="text", text=f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {stats['error']}")]
            
            # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
            total_size = stats.get('total_size', 0)
            if total_size > 1024 * 1024:  # MB
                size_str = f"{total_size / (1024 * 1024):.1f} MB"
            elif total_size > 1024:  # KB
                size_str = f"{total_size / 1024:.1f} KB"
            else:
                size_str = f"{total_size} å­—èŠ‚"
            
            response = f"""# ğŸ’¾ ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯

## ğŸ“Š æ¦‚è§ˆ
- ç¼“å­˜é¡¹ç›®æ•°: {stats.get('cached_projects', 0)}
- ç¼“å­˜æ€»å¤§å°: {size_str}
- ç¼“å­˜ç›®å½•: {stats.get('cache_dir', 'N/A')}

## ğŸ“ ç¼“å­˜é¡¹ç›®åˆ—è¡¨
"""
            
            projects = stats.get('projects', [])
            if projects:
                for i, project_key in enumerate(projects, 1):
                    response += f"{i}. {project_key}\n"
            else:
                response += " æš‚æ— ç¼“å­˜é¡¹ç›®"
            
            response += "\n\n **æç¤º**: ä½¿ç”¨ `clear_cache` å·¥å…·å¯ä»¥æ¸…é™¤ç¼“å­˜"
            
            return [TextContent(type="text", text=response)]
            
        except Exception as e:
            return [TextContent(type="text", text=f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {str(e)}")]

    async def _list_user_projects(self, args: Dict[str, Any]) -> Sequence[TextContent]:
        """åˆ—å‡ºæŒ‡å®šç”¨æˆ·çš„æ‰€æœ‰é¡¹ç›®ï¼Œè¿”å›é¡¹ç›®çš„ç»å¯¹è·¯å¾„"""
        try:
            username = args.get('username')
            
            # ä½¿ç”¨PathResolverè·å–ç”¨æˆ·é¡¹ç›®åˆ—è¡¨
            projects = self.path_resolver.list_user_projects(username)
            
            if not projects:
                if username:
                    return [TextContent(type="text", text=f"ç”¨æˆ· '{username}' æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é¡¹ç›®")]
                else:
                    return [TextContent(type="text", text="æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é¡¹ç›®")]
            
            # æ„å»ºå“åº”ï¼Œé‡ç‚¹çªå‡ºç»å¯¹è·¯å¾„
            response = f"# ğŸ“ ç”¨æˆ·é¡¹ç›®åˆ—è¡¨\n\n"
            
            if username:
                response += f"**ç”¨æˆ·**: {username}\n"
            else:
                response += f"**ç”¨æˆ·**: {self.path_resolver.default_username or 'é»˜è®¤ç”¨æˆ·'}\n"
            
            response += f"**é¡¹ç›®æ•°é‡**: {len(projects)}\n\n"
            response += "## é¡¹ç›®ç»å¯¹è·¯å¾„åˆ—è¡¨\n\n"
            
            for i, project in enumerate(projects, 1):
                project_name = project.get('name', 'Unknown')
                project_path = project.get('path', 'Unknown')
                is_git_repo = project.get('is_git_repo', False)
                
                git_indicator = " " if is_git_repo else ""
                response += f"{i}. **{project_name}**{git_indicator}\n"
                response += f"    `{project_path}`\n\n"
            
            response += "\n **æç¤º**: è¿™äº›æ˜¯é¡¹ç›®çš„å®Œæ•´ç»å¯¹è·¯å¾„ï¼Œå¯ä»¥ç›´æ¥ç”¨äº `analyze_project` å·¥å…·"
            
            return [TextContent(type="text", text=response)]
            
        except Exception as e:
            logger.error(f"åˆ—å‡ºç”¨æˆ·é¡¹ç›®å¤±è´¥: {e}")
            return [TextContent(type="text", text=f"åˆ—å‡ºç”¨æˆ·é¡¹ç›®å¤±è´¥: {str(e)}")]

def main():
    """MCPæœåŠ¡å™¨ä¸»å…¥å£ (HTTPç‰ˆæœ¬)"""
    # è®¾ç½®æ§åˆ¶å°è¾“å‡ºç¼–ç 
    import os
    os.environ.setdefault('PYTHONIOENCODING', 'utf-8')
    
    # è®¾ç½® sys.stdout ç¼–ç 
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')
    if hasattr(sys.stderr, 'reconfigure'):
        sys.stderr.reconfigure(encoding='utf-8')
    
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    host = os.getenv('MCP_SERVER_HOST', '0.0.0.0')
    port = int(os.getenv('MCP_SERVER_PORT', '8000'))
    
    server_instance = TreeSitterMCPServer()
    
    if MCP_AVAILABLE:
        # ä½¿ç”¨æ ‡å‡†MCPåè®® over SSE
        # sse = SseServerTransport("/messages/")
        sse = CustomSseWrapper("/messages/")
        
        async def handle_sse(request):
            async with sse.connect_sse(request.scope, request.receive, request._send) as streams:
                await server_instance.server.run(
                    streams[0],
                    streams[1],
                    InitializationOptions(
                        server_name="tree-sitter-code-analyzer",
                        server_version="1.0.0",
                        capabilities={}
                    )
                )
            return Response()  # é¿å… NoneType é”™è¯¯
        
        async def health_check(request):
            """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
            return Response(
                content='{"status": "healthy", "service": "tree-sitter-mcp-analyzer"}',
                media_type="application/json"
            )
        
        routes = [
            Route("/mcp", endpoint=handle_sse, methods=["GET"]),
            Route("/health", endpoint=health_check, methods=["GET"]),
            Mount("/messages", app=sse.handle_post_message),
        ]
        
        app = Starlette(routes=routes)
        
        print("ğŸš€ HTTP MCPæœåŠ¡å™¨å¯åŠ¨ä¸­...")
        print(f"ğŸ“ è®¿é—®ç«¯ç‚¹: http://{host}:{port}/mcp")
        print("ğŸ’¡ ä½¿ç”¨MCPå®¢æˆ·ç«¯è¿æ¥è¿›è¡Œå·¥å…·è°ƒç”¨")
        
        uvicorn.run(app, host=host, port=port)
    else:
        # ç®€åŒ–å®ç°æ¨¡å¼
        print("ğŸš€ Tree-Sitterä»£ç åˆ†æå™¨ (ç®€åŒ–æ¨¡å¼)")
        print("ğŸ“ è¦è·å¾—å®Œæ•´MCPåè®®æ”¯æŒï¼Œè¯·å®‰è£…: pip install mcp==1.0.0")
        print("âš¡ æœåŠ¡å™¨åŠŸèƒ½å·²å°±ç»ªï¼Œå¯ä»¥é€šè¿‡ç¨‹åºæ¥å£è°ƒç”¨")
        
        # åœ¨ç®€åŒ–æ¨¡å¼ä¸‹ï¼Œå¯ä»¥æä¾›ä¸€ä¸ªåŸºæœ¬çš„å‘½ä»¤è¡Œæ¥å£ç”¨äºæµ‹è¯•
        async def simple_demo():
            print("\n è¿è¡Œç®€å•æ¼”ç¤º...")
            try:
                # æ¼”ç¤ºåˆ†æç¤ºä¾‹é¡¹ç›®
                result = await server_instance._analyze_project({
                    "project_path": "examples",
                    "compress": True
                })
                
                if result and len(result) > 0:
                    print(" æ¼”ç¤ºåˆ†ææˆåŠŸ!")
                    print(result[0].text[:300] + "..." if len(result[0].text) > 300 else result[0].text)
                else:
                    print(" æ¼”ç¤ºåˆ†æå¤±è´¥")
            except Exception as e:
                print(f" æ¼”ç¤ºå‡ºé”™: {e}")
        
        asyncio.run(simple_demo())

if __name__ == "__main__":
    main()